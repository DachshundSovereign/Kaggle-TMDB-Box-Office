{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Model\n",
    "#### Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Hsieh/anaconda/lib/python3.5/site-packages/lightgbm/__init__.py:45: FutureWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS will be built by the Apple Clang compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you won't need to install the gcc compiler anymore.\n",
      "Instead of that, you'll need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from hyperopt import fmin, tpe, hp\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_folder = os.getcwd() + '/../dataset/'\n",
    "train = pd.read_csv('../dataset/2019-02-27_19-31_processed_train.csv', index_col=0)\n",
    "test = pd.read_csv('../dataset/2019-02-27_19-31_processed_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = train.drop(['revenue'], axis=1).values\n",
    "y = np.log(train.revenue.values + 1)\n",
    "X_test = test.drop(['revenue'], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RandomForestRegressor\n",
    "params = {'n_jobs': 4,\n",
    "          'n_estimators': 500,\n",
    "          'criterion': hp.choice('criterion', ['mse']), \n",
    "          'max_depth': hp.choice('max_depth', np.arange(5, 15, dtype=int)),\n",
    "          'min_samples_split': hp.uniform('min_samples_split', 0, 0.5),\n",
    "          'min_samples_leaf': hp.uniform('min_samples_leaf', 0, 0.5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# XGBRegressor\n",
    "params = {'silent': True,\n",
    "          'n_estimators': 500, \n",
    "          'objective': 'reg:linear',\n",
    "          'learning_rate': hp.uniform('learning_rate', 0, 0.1),  \n",
    "          'colsample_bytree': hp.uniform('colsample_bytree', 0, 0.5),\n",
    "          'subsample': hp.uniform('subsample', 0, 0.5),\n",
    "          'max_depth': hp.choice('max_depth', np.arange(5, 15, dtype=int))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CatBoostRegressor\n",
    "params = {'iterations': 1000,\n",
    "          'eval_metric': 'RMSE',\n",
    "          'early_stopping_rounds': 200,\n",
    "          'metric_period': None,\n",
    "          'depth': hp.choice('depth', np.arange(5, 15, dtype=int)),\n",
    "          'learning_rate': hp.uniform('learning_rate', 0, 0.1),\n",
    "          'colsample_bylevel': hp.uniform('colsample_bylevel', 0, 0.75),\n",
    "          'bagging_temperature': hp.uniform('bagging_temperature', 0, 0.25)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LGBMRegressor\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': hp.choice('max_depth', np.arange(5, 15, dtype=int)),\n",
    "          'learning_rate': hp.uniform('learning_rate', 0, 0.1),\n",
    "          'bagging_fraction': hp.uniform('bagging_fraction', 0.25, 0.75),\n",
    "          'num_leaves': hp.choice('num_leaves', np.array([50, 100, 150, 200, 250, 500, 750, 1000])),\n",
    "          'min_data_in_leaf' : hp.choice('min_data_in_leaf', np.array([10, 20, 30, 40, 50, 100]))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def KfoldCV(args): \n",
    "    \n",
    "    rmlse_score = list()\n",
    "    kf = KFold(n_splits=4)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        #model = RandomForestRegressor(**args)\n",
    "        #model = CatBoostRegressor(**args)\n",
    "        model = LGBMRegressor(**args)\n",
    "        #model = XGBRegressor(**args)\n",
    "        model.fit(X_train, y_train, verbose=False)\n",
    "        \n",
    "        pred = model.predict(X_test)\n",
    "        pred[pred < 0] = 0        \n",
    "        \n",
    "        rmlse_score.append(np.sqrt(mean_squared_error(pred, y_test)))\n",
    "    \n",
    "    return np.mean(rmlse_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters of best prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:55<00:00,  3.14s/it, best loss: 1.914983419072453]\n",
      "Best estimate parameters:  {'min_data_in_leaf': 0, 'learning_rate': 0.010147824037812225, 'bagging_fraction': 0.42683766871913165, 'max_depth': 2, 'num_leaves': 4}\n"
     ]
    }
   ],
   "source": [
    "best = fmin(KfoldCV, params, algo=tpe.suggest, max_evals=50)\n",
    "print(\"Best estimate parameters: \", best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model based on the parameters found"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Submission #001\n",
    "model = RandomForestRegressor(n_estimators=500,\n",
    "                              max_depth=9, \n",
    "                              min_samples_leaf=0.002,\n",
    "                              min_samples_split=0.027)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Submission #002\n",
    "model = RandomForestRegressor(n_estimators=500,\n",
    "                              max_depth=8, \n",
    "                              min_samples_leaf=0.004,\n",
    "                              min_samples_split=0.007)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Submission #003\n",
    "model = XGBRegressor(silent=False, \n",
    "                     scale_pos_weight=1,\n",
    "                     learning_rate=0.01,  \n",
    "                     colsample_bytree = 0.4,\n",
    "                     subsample = 0.8,\n",
    "                     objective='reg:linear', \n",
    "                     n_estimators=500, \n",
    "                     reg_alpha = 0.3,\n",
    "                     max_depth=4, \n",
    "                     gamma=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Submission #004\n",
    "model = CatBoostRegressor(iterations=1000,\n",
    "                          eval_metric='RMSE',\n",
    "                          early_stopping_rounds=200,\n",
    "                          metric_period=None,\n",
    "                          depth=3,\n",
    "                          learning_rate=0.043,\n",
    "                          colsample_bylevel=0.153,\n",
    "                          bagging_temperature=0.063)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Submission #005\n",
    "model = XGBRegressor(silent=True,\n",
    "                     objective='reg:linear', \n",
    "                     n_estimators=500,\n",
    "                     learning_rate=0.021,  \n",
    "                     colsample_bytree = 0.394,\n",
    "                     subsample = 0.466,\n",
    "                     max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Submission #006\n",
    "model = LGBMRegressor(n_estimators=500,\n",
    "                      min_data_in_leaf=10, \n",
    "                      learning_rate=0.0100,\n",
    "                      bagging_fraction=0.427,\n",
    "                      max_depth=7,\n",
    "                      num_leaves=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model to all training dataset and make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.22689101586\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y)\n",
    "print(np.sqrt(mean_squared_error(model.predict(X), y)))\n",
    "submission = (np.e ** model.predict(X_test) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Output submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time = datetime.datetime.now()\n",
    "time = '{:4d}-{:02d}-{:02d}_{:02d}-{:02d}'.format(time.year, time.month, time.day, time.hour, time.minute)\n",
    "\n",
    "submission = pd.DataFrame({'id': np.arange(3001, 7399), 'revenue': submission})\n",
    "submission.to_csv(dataset_folder + time + '_submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(dataset_folder + time + '_model.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
